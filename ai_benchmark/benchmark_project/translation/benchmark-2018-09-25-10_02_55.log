STARTING TIMING RUN AT 2018-09-25 02:02:56 AM
running benchmark with seed 1
INFO:tensorflow:Creating directory processed_data
INFO:tensorflow:Step 1/4: Downloading data from source
INFO:tensorflow:Already downloaded and extracted http://data.statmt.org/wmt17/translation-task/training-parallel-nc-v12.tgz.
INFO:tensorflow:Already downloaded and extracted http://www.statmt.org/wmt13/training-parallel-commoncrawl.tgz.
INFO:tensorflow:Already downloaded and extracted http://www.statmt.org/wmt13/training-parallel-europarl-v7.tgz.
INFO:tensorflow:Already downloaded and extracted http://data.statmt.org/wmt17/translation-task/dev.tgz.
INFO:tensorflow:Step 2/4: Creating subtokenizer and building vocabulary
INFO:tensorflow:Begin steps to create subtoken vocabulary...
INFO:tensorflow:Using min_count=6 to generate vocab with target size 32768
INFO:tensorflow:	Generating subtokens: iteration 0
INFO:tensorflow:	Vocab size: 96533
INFO:tensorflow:	Generating subtokens: iteration 1
INFO:tensorflow:	Vocab size: 33244
INFO:tensorflow:	Generating subtokens: iteration 2
INFO:tensorflow:	Vocab size: 34072
INFO:tensorflow:	Generating subtokens: iteration 3
INFO:tensorflow:	Vocab size: 33945
INFO:tensorflow:Generated vocabulary with 33945 subtokens.
INFO:tensorflow:Initializing Subtokenizer from file processed_data/vocab.ende.32768.
INFO:tensorflow:Step 3/4: Compiling training and evaluation data
INFO:tensorflow:Compiling files with tag train.
INFO:tensorflow:Reading files /raw_data/training/news-commentary-v12.de-en.en and /raw_data/training/news-commentary-v12.de-en.de.
INFO:tensorflow:Reading files /raw_data/commoncrawl.de-en.en and /raw_data/commoncrawl.de-en.de.
INFO:tensorflow:Reading files /raw_data/training/europarl-v7.de-en.en and /raw_data/training/europarl-v7.de-en.de.
INFO:tensorflow:Compiling files with tag dev.
INFO:tensorflow:Reading files /raw_data/dev/newstest2013.en and /raw_data/dev/newstest2013.de.
INFO:tensorflow:Step 4/4: Preprocessing and saving data
INFO:tensorflow:Saving files with tag train.
INFO:tensorflow:	Saving case 100000.
INFO:tensorflow:	Saving case 200000.
INFO:tensorflow:	Saving case 300000.
INFO:tensorflow:	Saving case 400000.
INFO:tensorflow:	Saving case 500000.
INFO:tensorflow:	Saving case 600000.
INFO:tensorflow:	Saving case 700000.
INFO:tensorflow:	Saving case 800000.
INFO:tensorflow:	Saving case 900000.
INFO:tensorflow:	Saving case 1000000.
INFO:tensorflow:	Saving case 1100000.
INFO:tensorflow:	Saving case 1200000.
^CTraceback (most recent call last):
  File "process_data.py", line 418, in <module>
    main(sys.argv)
  File "process_data.py", line 391, in main
    _TRAIN_SHARDS)
  File "process_data.py", line 295, in encode_and_save_files
    "targets": subtokenizer.encode(target_line, add_eos=True)})
  File "process_data.py", line 346, in dict_to_example
    return tf.train.Example(features=tf.train.Features(feature=features))
KeyboardInterrupt
^C